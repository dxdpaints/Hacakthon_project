{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_UNYwWqr-n1d",
        "outputId": "9c5bb641-2128-481b-e3c8-dc285c176371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 109 images belonging to 2 classes.\n",
            "Found 109 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 169s 44s/step - loss: 7.2992 - accuracy: 0.4862 - val_loss: 2.6067 - val_accuracy: 0.4587\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 163s 43s/step - loss: 1.3249 - accuracy: 0.5321 - val_loss: 0.6882 - val_accuracy: 0.5688\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 158s 48s/step - loss: 0.6289 - accuracy: 0.6514 - val_loss: 0.5210 - val_accuracy: 0.7339\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 164s 44s/step - loss: 0.4667 - accuracy: 0.7798 - val_loss: 0.3377 - val_accuracy: 0.8807\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 170s 44s/step - loss: 0.4203 - accuracy: 0.7890 - val_loss: 0.2319 - val_accuracy: 0.8899\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 163s 43s/step - loss: 0.3065 - accuracy: 0.8716 - val_loss: 0.1779 - val_accuracy: 0.9266\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 161s 42s/step - loss: 0.2202 - accuracy: 0.9174 - val_loss: 0.1607 - val_accuracy: 0.9174\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 166s 51s/step - loss: 0.1234 - accuracy: 0.9633 - val_loss: 0.1005 - val_accuracy: 0.9633\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 168s 44s/step - loss: 0.1334 - accuracy: 0.9541 - val_loss: 0.0726 - val_accuracy: 0.9725\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 171s 45s/step - loss: 0.0711 - accuracy: 0.9817 - val_loss: 0.0617 - val_accuracy: 0.9541\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 224, 3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cc72418866eb>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/clean.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_cleanliness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted cleanliness:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-cc72418866eb>\u001b[0m in \u001b[0;36mpredict_cleanliness\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;31m# img = cv2.expand_dims(img, axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Clean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers[:-2]:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "model.fit(train_generator,\n",
        "          epochs=10,\n",
        "          validation_data=validation_generator)\n",
        "\n",
        "model.save('final_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# loaded_model = load_model(\"final_model.h5\")\n",
        "# def predict_cleanliness(img_path, model):\n",
        "#     img = cv2.imread(img_path)\n",
        "#     img = cv2.resize(img, (224, 224))  # Reshape to match model input\n",
        "#     img = img.astype(\"float32\") / 255.0  # Normalize pixel values\n",
        "#     img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "#     pred = model.predict(img)[0][0]\n",
        "#     print(pred)\n",
        "#     if pred > 0.9:\n",
        "#         return \"Clean\"\n",
        "#     else:\n",
        "#         return \"Messy\"\n",
        "\n",
        "# new_image = \"/content/clean.jpg\"\n",
        "# prediction = predict_cleanliness(new_image, loaded_model)\n",
        "# print(\"Predicted cleanliness:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPRDJ92PY-3D",
        "outputId": "b69effb8-a04d-42a8-ed28-a26d7bcf50ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 634ms/step\n",
            "0.7983789\n",
            "Predicted cleanliness: Messy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "from pillow_heif import register_heif_opener\n",
        "register_heif_opener()\n",
        "import numpy as np\n",
        "\n",
        "loaded_model = load_model(\"final_model.h5\")\n",
        "\n",
        "def predict_cleanliness(img_path, model):\n",
        "  try:\n",
        "      img = Image.open(img_path)\n",
        "      img = img.convert('RGB')\n",
        "      img = img.resize((224, 224))\n",
        "      img_data = np.array(img)\n",
        "      img_data = img_data.astype(\"float32\") / 255.0\n",
        "      img_data = np.expand_dims(img_data, axis=0)\n",
        "      pred = model.predict(img_data)[0][0]\n",
        "      print(pred)\n",
        "      if pred > 0.9:\n",
        "          return \"Messy\"\n",
        "      else:\n",
        "          return \"Clean\"\n",
        "  except Exception as e:\n",
        "      return (f\"Error reading image {img_path}: {e}\")\n",
        "\n",
        "# Example usage with the loaded model\n",
        "new_image = \"/content/IMG_0885.HEIC\"  # Or a HEIF image path\n",
        "prediction = predict_cleanliness(new_image, loaded_model)\n",
        "print(\"Predicted cleanliness:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rISt3B8XdDq3",
        "outputId": "85b2bb4a-7dbd-447b-d8a9-9ad8723c59df"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 604ms/step\n",
            "0.5538965\n",
            "Predicted cleanliness: Clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cKz4iCp8BHzI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}